{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0a7a50",
   "metadata": {},
   "source": [
    "# Classification with Tabular Data using H2OAutoML and Cleanlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc8e281",
   "metadata": {},
   "source": [
    "This notebook is based on the following two tutorial notebooks.\n",
    "\n",
    "- [cleanlab/docs/source/tutorials/tabular.ipynb](https://github.com/cleanlab/cleanlab/blob/0dc384a4edfba31500e672b15026b781ea952f91/docs/source/tutorials/tabular.ipynb)\n",
    "- [h2o-tutorials/tutorials/sklearn-integration/H2OAutoML_as_sklearn_estimator.ipynb](https://github.com/h2oai/h2o-tutorials/blob/7c8fca34b2bf26870be71232ade52472a087f0ad/tutorials/sklearn-integration/H2OAutoML_as_sklearn_estimator.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52818182",
   "metadata": {},
   "source": [
    "In this tutorial, we will use `cleanlab` with `H2OAutoML` models to find potential label errors in the German Credit dataset. This dataset contains 1,000 individuals described by 20 features, each labeled as either \"good\" or \"bad\" credit risk. `cleanlab` automatically shortlists examples from this dataset that confuse our ML model; many of which are potential label errors (due to annotator mistakes), edge cases, and otherwise ambiguous examples.\n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Build a simple credit risk classifier with `H2OAutoML`.\n",
    "\n",
    "- Use this classifier to compute out-of-sample predicted probabilities, `pred_probs`, via cross validation.\n",
    "\n",
    "- Identify potential label errors in the data with `cleanlab`'s `find_label_issues` method.\n",
    "\n",
    "- Train a robust version of the same `H2OAutoML` model via `cleanlab`'s `CleanLearning` wrapper.\n",
    "\n",
    "**Data:** https://www.openml.org/d/31\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2e2a17",
   "metadata": {},
   "source": [
    "## **1. Install required dependencies**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4016121d",
   "metadata": {},
   "source": [
    "You can use `conda` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```\n",
    "!conda env update -n cleanlab-h2oautoml -f ./conda-env.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee6f5e1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 123456\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63306542",
   "metadata": {},
   "source": [
    "## **2. Load and process the data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded667e",
   "metadata": {},
   "source": [
    "We first load the data features and labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e047405",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(\"credit-g\")  # get the credit data from OpenML\n",
    "X_raw = data.data  # features (pandas DataFrame)\n",
    "y_raw = data.target  # labels (pandas Series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25177c32",
   "metadata": {},
   "source": [
    "Next we preprocess the data. Here we apply one-hot encoding to features with categorical data, and standardize features with numeric data. We also perform label encoding on the labels - \"bad\" is encoded as 0 and \"good\" is encoded as 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163eb34f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cat_features = X_raw.select_dtypes(\"category\").columns\n",
    "X_encoded = pd.get_dummies(X_raw, columns=cat_features, drop_first=True)\n",
    "\n",
    "num_features = X_raw.select_dtypes(\"float64\").columns\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X_encoded.copy()\n",
    "X_scaled[num_features] = scaler.fit_transform(X_encoded[num_features])\n",
    "X_scaled = X_scaled.to_numpy()\n",
    "\n",
    "y = y_raw.map({\"bad\": 0, \"good\": 1})  # encode labels as integers\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b72eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Bringing Your Own Data (BYOD)?\n",
    "\n",
    "You can easily replace the above with your own tabular dataset, and continue with the rest of the tutorial.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d735c7b",
   "metadata": {},
   "source": [
    "## **3. Select a classification model and compute out-of-sample predicted probabilities**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da64ac",
   "metadata": {},
   "source": [
    "Here we use `H2OAutoML`, but you can choose _any_ suitable scikit-learn model for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6a6ba",
   "metadata": {},
   "source": [
    "To identify label issues, `cleanlab` requires a probabilistic prediction from your model for every datapoint. However, these predictions will be _overfitted_ (and thus unreliable) for examples the model was previously trained on. `cleanlab` is intended to only be used with **out-of-sample** predicted probabilities, i.e., on examples held out from the model during the training.\n",
    "\n",
    "K-fold cross-validation is a straightforward way to produce out-of-sample predicted probabilities for every datapoint in the dataset by training K copies of our model on different data subsets and using each copy to predict on the subset of data it did not see during training. An additional benefit of cross-validation is that it provides a more reliable evaluation of our model than a single training/validation split. We can obtain cross-validated out-of-sample predicted probabilities from any classifier via a simple scikit-learn wrapper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55dfa29f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from h2o.sklearn import H2OAutoMLClassifier\n",
    "clf = H2OAutoMLClassifier(max_runtime_secs=5, sort_metric='aucpr', keep_cross_validation_predictions=True, nfolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94ea692",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>7 hours 54 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Tokyo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>11 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_kon_mgtoet</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.114 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.13 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         7 hours 54 mins\n",
       "H2O_cluster_timezone:       Asia/Tokyo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.0.4\n",
       "H2O_cluster_version_age:    11 days\n",
       "H2O_cluster_name:           H2O_from_python_kon_mgtoet\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.114 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:11:23.716: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███\n",
      "17:11:24.723: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████\n",
      "17:11:25.741: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:11:26.760: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "█████████████████████████\n",
      "17:11:27.778: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_scaled, y)\n",
    "pred_probs = clf.predict_proba(X_scaled)\n",
    "pred_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ae6a0",
   "metadata": {},
   "source": [
    "## **4. Use cleanlab to find label issues**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a54803",
   "metadata": {},
   "source": [
    "Based on the given labels and out-of-sample predicted probabilities, `cleanlab` can quickly help us identify label issues in our dataset. Here we request that the indices of the identified label issues be sorted by `cleanlab`'s self-confidence score, which measures the quality of each given label via the probability assigned to it in our model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9890ba05",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanlab found 105 potential label errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([505, 757, 228,  80, 949, 190,  92, 754, 335, 963, 614, 412, 647,\n",
       "       598, 435, 796, 278, 272, 780, 763, 846, 331, 175, 642, 409, 543,\n",
       "       137, 589,  56, 861, 864, 978, 559, 936, 900, 357, 351, 213, 485,\n",
       "       700, 457, 621, 735, 966, 674, 302, 195, 249, 611, 980, 424, 285,\n",
       "       818, 650, 208, 945, 229, 808, 815, 141, 876,  17, 615, 623, 221,\n",
       "       687, 896, 869, 111, 986, 658, 417, 866, 926, 704, 395, 340, 145,\n",
       "       338, 605, 367, 743,  14, 740, 666, 829, 703,  31, 152, 616, 392,\n",
       "       101, 573, 438, 201, 130, 481, 163, 189, 678, 612, 934, 985, 993,\n",
       "       959])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "ranked_label_issues = find_label_issues(\n",
    "    labels=y, pred_probs=pred_probs, return_indices_ranked_by=\"self_confidence\"\n",
    ")\n",
    "\n",
    "print(f\"Cleanlab found {len(ranked_label_issues)} potential label errors.\")\n",
    "ranked_label_issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b7ca4e",
   "metadata": {},
   "source": [
    "Let's review some of the most likely label errors:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc7eca19",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>no checking</td>\n",
       "      <td>10.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>new car</td>\n",
       "      <td>1309.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>life insurance</td>\n",
       "      <td>27.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unskilled resident</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>&gt;=200</td>\n",
       "      <td>15.0</td>\n",
       "      <td>critical/other existing credit</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>1&lt;=X&lt;4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>no known property</td>\n",
       "      <td>39.0</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>no checking</td>\n",
       "      <td>9.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1478.0</td>\n",
       "      <td>&lt;100</td>\n",
       "      <td>4&lt;=X&lt;7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>22.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>no checking</td>\n",
       "      <td>24.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5943.0</td>\n",
       "      <td>no known savings</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female div/dep/mar</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>44.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>no checking</td>\n",
       "      <td>24.0</td>\n",
       "      <td>existing paid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>3621.0</td>\n",
       "      <td>100&lt;=X&lt;500</td>\n",
       "      <td>&gt;=7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>male single</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>31.0</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2.0</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    checking_status  duration                  credit_history   purpose  \\\n",
       "505     no checking      10.0                   existing paid   new car   \n",
       "757           >=200      15.0  critical/other existing credit  radio/tv   \n",
       "228     no checking       9.0                   existing paid  radio/tv   \n",
       "80      no checking      24.0                   existing paid  radio/tv   \n",
       "949     no checking      24.0                   existing paid  radio/tv   \n",
       "\n",
       "     credit_amount    savings_status employment  installment_commitment  \\\n",
       "505         1309.0  no known savings     1<=X<4                     4.0   \n",
       "757         1271.0  no known savings     1<=X<4                     3.0   \n",
       "228         1478.0              <100     4<=X<7                     4.0   \n",
       "80          5943.0  no known savings         <1                     1.0   \n",
       "949         3621.0        100<=X<500        >=7                     2.0   \n",
       "\n",
       "        personal_status other_parties  ...  property_magnitude   age  \\\n",
       "505         male single     guarantor  ...      life insurance  27.0   \n",
       "757         male single          none  ...   no known property  39.0   \n",
       "228         male single          none  ...                 car  22.0   \n",
       "80   female div/dep/mar          none  ...                 car  44.0   \n",
       "949         male single          none  ...                 car  31.0   \n",
       "\n",
       "     other_payment_plans   housing existing_credits                 job  \\\n",
       "505                 none       own              1.0  unskilled resident   \n",
       "757                 none  for free              2.0             skilled   \n",
       "228                 none       own              1.0             skilled   \n",
       "80                  none       own              2.0             skilled   \n",
       "949                 none       own              2.0             skilled   \n",
       "\n",
       "    num_dependents  own_telephone foreign_worker label  \n",
       "505            1.0           none            yes   bad  \n",
       "757            1.0            yes            yes   bad  \n",
       "228            1.0           none            yes   bad  \n",
       "80             1.0            yes            yes   bad  \n",
       "949            1.0           none            yes   bad  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.iloc[ranked_label_issues].assign(label=y_raw.iloc[ranked_label_issues]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e72eb",
   "metadata": {},
   "source": [
    "These examples appear the most suspicious to our model and should be carefully re-examined. Perhaps the original annotators missed something when deciding on the labels for these individuals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cd37c",
   "metadata": {},
   "source": [
    "## **5. Train a more robust model from noisy labels**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fdfb1b",
   "metadata": {},
   "source": [
    "Following proper ML practice, let's split our data into train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3fe597f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c24cc",
   "metadata": {},
   "source": [
    "We again standardize the numeric features, this time fitting the scaling parameters solely on the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75503c8c",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52d0cd",
   "metadata": {},
   "source": [
    "Let's now train and evaluate the original `H2OAutoML` model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d52256",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_b81d closed.\n",
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>7 hours 54 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Tokyo</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.36.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>11 days </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_kon_mgtoet</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.098 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.13 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         7 hours 54 mins\n",
       "H2O_cluster_timezone:       Asia/Tokyo\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.36.0.4\n",
       "H2O_cluster_version_age:    11 days\n",
       "H2O_cluster_name:           H2O_from_python_kon_mgtoet\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.098 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:11:30.767: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███\n",
      "17:11:31.775: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████\n",
      "17:11:32.790: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:11:33.804: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "█████████████████████████\n",
      "17:11:34.821: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Test accuracy of original H2OAutoML: 0.736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = H2OAutoMLClassifier(max_runtime_secs=5, sort_metric='aucpr', keep_cross_validation_predictions=True, nfolds=3)\n",
    "clf.fit(X_train, y_train)\n",
    "acc_og = clf.score(X_test, y_test)\n",
    "print(f\"Test accuracy of original H2OAutoML: {acc_og}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cae490c",
   "metadata": {},
   "source": [
    "`cleanlab` provides a wrapper class that can be easily applied to any scikit-learn compatible model. Once wrapped, the resulting model can still be used in the exact same manner, but it will now train more robustly if the data have noisy labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "062458c8",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from cleanlab.classification import CleanLearning\n",
    "\n",
    "clf = H2OAutoMLClassifier(max_runtime_secs=5, sort_metric='aucpr',\n",
    "    # keep_cross_validation_predictions=True, nfolds=3\n",
    ")\n",
    "cl = CleanLearning(clf)  # cl has same methods/attributes as clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f876470",
   "metadata": {},
   "source": [
    "The following operations take place when we train the `cleanlab`-wrapped model: The original model is trained in a cross-validated fashion to produce out-of-sample predicted probabilities. Then, these predicted probabilities are used to identify label issues, which are then removed from the dataset. Finally, the original model is trained on the remaining clean subset of the data once more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a3dede",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing out of sample predicted probabilites via 5-fold cross validation. May take a while ...\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:11:37.450: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███\n",
      "17:11:38.458: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████\n",
      "17:11:39.478: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:11:40.490: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "█████████████████████████\n",
      "17:11:41.507: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:11:43.805: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███\n",
      "17:11:44.811: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████\n",
      "17:11:45.822: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:11:46.846: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "████████████████████████\n",
      "17:11:47.865: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:11:49.914: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "█████████████\n",
      "17:11:51.922: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:11:52.932: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "█████████████████████████\n",
      "17:11:53.946: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "███████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:11:55.829: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "█████████████\n",
      "17:11:57.836: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:11:58.859: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████████████████\n",
      "17:11:59.878: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "██████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:12:01.913: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███\n",
      "17:12:02.920: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████\n",
      "17:12:03.938: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:12:04.955: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "█████████████████████████\n",
      "17:12:05.978: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "Using predicted probabilities to identify label issues ...\n",
      "Identified 118 examples with label issues.\n",
      "Pruning 118 examples with label issues ...\n",
      "Remaining clean data has 632 examples.\n",
      "Fitting final model on the clean data ...\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "17:12:07.785: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███\n",
      "17:12:08.792: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████\n",
      "17:12:09.812: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "██████████████\n",
      "17:12:10.834: _train param, Dropping unused columns: [C21, C36]\n",
      "\n",
      "█████████████████████████\n",
      "17:12:11.856: _train param, Dropping bad and constant columns: [C21, C36]\n",
      "\n",
      "███████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "H2OAutoMLClassifier(max_runtime_secs=5, sort_metric='aucpr')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82fc78",
   "metadata": {},
   "source": [
    "We can get predictions from the resulting model and evaluate them, just like how we did it for the original scikit-learn model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acbb5002",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Test accuracy of cleanlab's H2OAutoML: 0.764\n"
     ]
    }
   ],
   "source": [
    "preds = cl.predict(X_test)\n",
    "acc_cl = accuracy_score(y_test, preds)\n",
    "print(f\"Test accuracy of cleanlab's H2OAutoML: {acc_cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b02d2e",
   "metadata": {},
   "source": [
    "We can see that the test set accuracy slightly improved as a result of the data cleaning. Note that this will not always be the case, especially when we evaluate on test data that are themselves noisy. The best practice is to run `cleanlab` to identify potential label issues and then manually review them, before blindly trusting any accuracy metrics. In particular, the most effort should be made to ensure high-quality test data, which is supposed to reflect the expected performance of our model during deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47bb7673",
   "metadata": {
    "nbsphinx": "hidden",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Hidden code cell to check that cleanlab has improved prediction accuracy\n",
    "if acc_og >= acc_cl:\n",
    "    raise Exception(\"Cleanlab training failed to improve model accuracy.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "py,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
